{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "seed = 10\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "import eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_transaction = pd.read_csv('train_transaction.csv', index_col='TransactionID')\n",
    "test_transaction = pd.read_csv('test_transaction.csv', index_col='TransactionID')\n",
    "\n",
    "\n",
    "# train_transaction = reduce_mem_usage(train_transaction)\n",
    "# test_transaction = reduce_mem_usage(test_transaction)\n",
    "\n",
    "sample_submission = pd.read_csv('sample_submission.csv', index_col='TransactionID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction['hour'] = train_transaction['TransactionDT'].map(lambda x:(x//3600)%24)\n",
    "test_transaction['hour'] = test_transaction['TransactionDT'].map(lambda x:(x//3600)%24)\n",
    "train_transaction['weekday'] = train_transaction['TransactionDT'].map(lambda x:(x//(3600 * 24))%7)\n",
    "test_transaction['weekday'] = test_transaction['TransactionDT'].map(lambda x:(x//(3600 * 24))%7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = \"TransactionDT,TransactionAmt,ProductCD,card1,card2,card3,card4,card5,card6,addr1,addr2,C1,C2,C3,C4,C5,C6,C7,C8,C9,C10,C11,C12,C13,C14,M1,M2,M3,M4,M5,M6,M7,M8,M9\".split(\",\")\n",
    "train_test = train_transaction[cols].append(test_transaction[cols])\n",
    "\n",
    "for col in \"ProductCD,card1,card2,card3,card4,card5,card6,addr1,addr2,C1,C2,C3,C4,C5,C6,C7,C8,C9,C10,C11,C12,C13,C14\".split(\",\"):\n",
    "    col_count = train_test.groupby(col)['TransactionDT'].count()\n",
    "    train_transaction[col+'_count'] = train_transaction[col].map(col_count)\n",
    "    test_transaction[col+'_count'] = test_transaction[col].map(col_count)\n",
    "#     print(col,test_transaction[col].map(lambda x:0 if x in s else 1).sum())\n",
    "\n",
    "\n",
    "for col in \"card1,card2,card5,addr1,addr2\".split(\",\"):\n",
    "    col_count = train_test.groupby(col)['TransactionAmt'].mean()\n",
    "    train_transaction[col+'_amtcount'] = train_transaction[col].map(col_count)\n",
    "    test_transaction[col+'_amtcount'] = test_transaction[col].map(col_count)\n",
    "    col_count1 = train_test[train_test['C5'] == 0].groupby(col)['C5'].count()\n",
    "    col_count2 = train_test[train_test['C5'] != 0].groupby(col)['C5'].count()\n",
    "    train_transaction[col+'_C5count'] = train_transaction[col].map(col_count2) / (train_transaction[col].map(col_count1) + 0.01)\n",
    "    test_transaction[col+'_C5count'] = test_transaction[col].map(col_count2) / (test_transaction[col].map(col_count1) + 0.01)\n",
    "    \n",
    "del train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_identity = pd.read_csv('train_identity.csv', index_col='TransactionID')\n",
    "test_identity = pd.read_csv('test_identity.csv', index_col='TransactionID')\n",
    "\n",
    "\n",
    "# train_test = train_identity.append(test_identity).fillna(-1)    \n",
    "# for col in \"id_01,id_02,id_03,id_04,id_05,id_06,id_07,id_08,id_09,id_10,id_12,id_13,id_14,id_15,id_16,id_17,id_18,id_19,id_20,id_21,id_22,id_23,id_24,id_25,id_26,id_27,id_28,id_29,id_30,id_31,id_32,id_33,id_34,id_35,id_36,id_37,id_38,DeviceType,DeviceInfo\".split(\",\"):\n",
    "#     col_count = train_test.groupby(col)['id_01'].count()\n",
    "#     train_identity[col+'_count'] = train_identity[col].fillna(-1).map(col_count)\n",
    "#     test_identity[col+'_count'] = test_identity[col].fillna(-1).map(col_count)\n",
    "    \n",
    "# del train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V126 24875\n",
      "V127 104743\n",
      "V128 46447\n",
      "V129 8376\n",
      "V130 89202\n",
      "V131 29537\n",
      "V132 9116\n",
      "V133 14910\n",
      "V134 11134\n",
      "V135 9184\n",
      "V136 14824\n",
      "V137 10682\n",
      "V159 8116\n",
      "V160 10836\n",
      "V164 597\n",
      "V165 3440\n",
      "V166 2347\n",
      "V202 16120\n",
      "V203 20278\n",
      "V204 18198\n",
      "V205 6576\n",
      "V206 4897\n",
      "V207 9195\n",
      "V208 10054\n",
      "V209 10466\n",
      "V210 10210\n",
      "V211 10131\n",
      "V212 11253\n",
      "V213 10710\n",
      "V214 4277\n",
      "V215 5191\n",
      "V216 4769\n",
      "V263 16586\n",
      "V264 20089\n",
      "V265 18161\n",
      "V266 6886\n",
      "V267 10591\n",
      "V268 8642\n",
      "V270 8138\n",
      "V271 8432\n",
      "V272 8261\n",
      "V273 10568\n",
      "V274 11959\n",
      "V275 11161\n",
      "V276 4398\n",
      "V277 5417\n",
      "V278 4856\n",
      "V306 37081\n",
      "V307 140538\n",
      "V308 67074\n",
      "V309 16636\n",
      "V310 121258\n",
      "V311 10140\n",
      "V312 46506\n",
      "V313 50088\n",
      "V314 59747\n",
      "V315 51521\n",
      "V316 15081\n",
      "V317 24841\n",
      "V318 18718\n",
      "V319 10762\n",
      "V320 18664\n",
      "V321 13113\n"
     ]
    }
   ],
   "source": [
    "col_del = []\n",
    "for i in range(339):\n",
    "    col = \"V\" + str(i+1)\n",
    "    s = train_transaction[col].fillna(0).map(lambda x:0 if x%1 == 0 else 1).sum()\n",
    "    if s > 100:\n",
    "        print(col,s)\n",
    "        col_del.append(col)\n",
    "#         del test_transaction[col],train_transaction[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590540, 468)\n",
      "(506691, 467)\n"
     ]
    }
   ],
   "source": [
    "train = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\n",
    "test = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "y_train = train['isFraud'].copy()\n",
    "del train_transaction, train_identity, test_transaction, test_identity\n",
    "\n",
    "# Drop target, fill in NaNs\n",
    "X_train = train.drop('isFraud', axis=1)\n",
    "X_test = test.copy()\n",
    "\n",
    "del train, test\n",
    "\n",
    "# Label Encoding\n",
    "for f in X_train.columns:\n",
    "    if X_train[f].dtype=='object' or X_test[f].dtype=='object': \n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(X_train[f].values) + list(X_test[f].values))\n",
    "        X_train[f] = lbl.transform(list(X_train[f].values))\n",
    "        X_test[f] = lbl.transform(list(X_test[f].values)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 2128.56 MB\n",
      "Memory usage after optimization is: 610.22 MB\n",
      "Decreased by 71.3%\n",
      "Memory usage of dataframe is 1809.17 MB\n",
      "Memory usage after optimization is: 514.14 MB\n",
      "Decreased by 71.6%\n",
      "Wall time: 10min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# From kernel https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
    "# WARNING! THIS CAN DAMAGE THE DATA \n",
    "\n",
    "X_train = reduce_mem_usage(X_train)\n",
    "X_test = reduce_mem_usage(X_test)\n",
    "\n",
    "debug = False\n",
    "if debug:\n",
    "    split_pos = X_train.shape[0]*4//5\n",
    "    y_test = y_train.iloc[split_pos:]\n",
    "    y_train = y_train.iloc[:split_pos]\n",
    "    X_test = X_train.iloc[split_pos:,:]\n",
    "    X_train = X_train.iloc[:split_pos,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(590540, 467)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ProductCD', 'card1', 'card2', 'addr1', 'addr2', 'P_emaildomain', 'R_emaildomain', 'DeviceType', 'DeviceInfo']\n"
     ]
    },
    {
     "ename": "CatboostError",
     "evalue": "Invalid cat_features[0] = ProductCD value type=<class 'str'>: must be int().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCatboostError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-5a2e98bca1a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_tr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose_eval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_tr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose_eval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, cat_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval)\u001b[0m\n\u001b[0;32m   2181\u001b[0m         self._fit(X, y, cat_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0;32m   2182\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2183\u001b[1;33m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval)\n\u001b[0m\u001b[0;32m   2184\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, cat_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval)\u001b[0m\n\u001b[0;32m   1087\u001b[0m         \u001b[0m_check_train_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1088\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1089\u001b[1;33m         \u001b[0mtrain_pool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_build_train_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1090\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_empty_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCatboostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"X is empty.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_build_train_pool\u001b[1;34m(X, y, cat_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, column_description)\u001b[0m\n\u001b[0;32m    653\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCatboostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y has not initialized in fit(): X is not catboost.Pool object, y must be not None in fit().\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m         train_pool = Pool(X, y, cat_features=cat_features, pairs=pairs, weight=sample_weight, group_id=group_id,\n\u001b[1;32m--> 655\u001b[1;33m                           group_weight=group_weight, subgroup_id=subgroup_id, pairs_weight=pairs_weight, baseline=baseline)\n\u001b[0m\u001b[0;32m    656\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, label, cat_features, column_description, pairs, delimiter, has_header, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, feature_names, thread_count)\u001b[0m\n\u001b[0;32m    284\u001b[0m                         )\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_init\u001b[1;34m(self, data, label, cat_features, pairs, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, feature_names)\u001b[0m\n\u001b[0;32m    600\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcat_features\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_cf_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 602\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_cf_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    603\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpairs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_pairs_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_check_cf_value\u001b[1;34m(self, cat_features, features_count)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mindx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mINTEGER_TYPES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mCatboostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid cat_features[{}] = {} value type={}: must be int().\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mfeatures_count\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCatboostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid cat_features[{}] = {} value: must be < {}.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCatboostError\u001b[0m: Invalid cat_features[0] = ProductCD value type=<class 'str'>: must be int()."
     ]
    }
   ],
   "source": [
    "import catboost as cb\n",
    "from catboost import CatBoostClassifier,Pool\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "features = [x for x in X_train.columns]\n",
    "\n",
    "cate = [x for x in X_train.columns if (x == 'ProductCD' or x in ['card1','card2'] or x.startswith(\"addr\") or \n",
    "                                       x.endswith(\"domain\") or x.startswith(\"Device\")) and not x.endswith(\"count\") and not x == \"id_11\" ]\n",
    "\n",
    "# cate = []\n",
    "print(cate)\n",
    "verbose_eval = 30\n",
    "num_rounds = 800\n",
    "\n",
    "folds = 5\n",
    "kf = KFold(n_splits = folds, shuffle = True, random_state=seed+1)\n",
    "y_preds3 = np.zeros(X_test.shape[0])\n",
    "feature_importance_df = pd.DataFrame()\n",
    "i = 0\n",
    "for tr_idx, val_idx in kf.split(X_train, y_train):\n",
    "\n",
    "    \n",
    "    X_tr = X_train[features].iloc[tr_idx, :].fillna(-1)\n",
    "    y_tr = y_train.iloc[tr_idx]\n",
    "    \n",
    "    model=cb.CatBoostClassifier(iterations=num_rounds,depth=14,learning_rate=0.04,loss_function='Logloss',eval_metric='Logloss'\n",
    "                                ,task_type = \"GPU\")\n",
    "    if debug:\n",
    "        model.fit(X_tr,y_tr,cat_features=cate,verbose_eval = 30)\n",
    "    else:\n",
    "        model.fit(X_tr,y_tr,cat_features=cate,verbose_eval = 30)\n",
    "        \n",
    "\n",
    "    del X_tr\n",
    "    y_preds3+= model.predict_proba(X_test[features].fillna(-1))[:,1] / folds\n",
    "    \n",
    "    \n",
    "    if debug:    \n",
    "        print(\"debug:\",roc_auc_score(y_test, model.predict_proba(X_test[features].fillna(-1))[:,1] / folds))  \n",
    "    i+=1\n",
    "\n",
    "if debug:    \n",
    "    print(\"debug:\",roc_auc_score(y_test, y_preds3))  \n",
    "    print(\"debug:\",roc_auc_score(y_test, (y_preds + y_preds3)*0.5))  \n",
    "    print(\"debug:\",roc_auc_score(y_test, (y_preds + y_preds2 + y_preds3)*0.33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
